{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from dotenv import load_dotenv \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read XSD from 1872.1-2024\n",
    "with open('app/resources/context/wheeled_bots/schema.xsd', 'r') as file:\n",
    "    schema = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read XSD from 1872.1-2024\n",
    "with open('app/resources/context/wheeled_bots/reza_medium.geojson', 'r') as file:\n",
    "    geojson = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global environment config\n",
    "load_dotenv('/Users/marcos/.gpt/token.env')\n",
    "MAX_TOKENS: int = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a mission planner that generates XML mission plans based on robotic task representation. \\\n",
    "            When asked to generate a mission, create an XML file conformant to the known schema and use the GeoJSON file to provide references in the mission plan for things such as GPS location, tree type, etc. \\\n",
    "            It must be syntactically correct and validate using an XML linter.\",\n",
    "    },\n",
    "    # context\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"This is the schema for which you must generate mission plan XML documents:\" + schema\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"If you have any specific questions or modifications you'd like to discuss regarding this schema, feel free to ask!\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"This is the GeoJSON for which you must generate mission plan XML documents. This is our orchard:\" + geojson\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Thank you for providing the GeoJSON file. I'll assist you in creating the XML file for your robotic mission plan when you provide your mission.\"\n",
    "    },\n",
    "    # TODO: add context of farm layout so that machine can generate XML with relevant state information\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"Make a plan to take a picture of every other pistachio tree.\"\n",
    "message = {\"role\": \"user\", \"content\": m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(messages):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o\", messages=messages, max_tokens=MAX_TOKENS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = ask_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as fp:\n",
    "    fp.write(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_response = completion.choices[0].message.content\n",
    "\n",
    "xml_response = gpt_response.split(\"```xml\\n\")[1]\n",
    "xml_response = xml_response.split(\"```\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('app/gpt_outputs/gpt_example.xml', 'w') as fp:\n",
    "    fp.write(xml_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_xml(xsd_file, xml_file) -> str:\n",
    "    try:\n",
    "        # Parse the XSD file\n",
    "        with open(xsd_file, 'rb') as schema_file:\n",
    "            schema_root = etree.XML(schema_file.read())\n",
    "        schema = etree.XMLSchema(schema_root)\n",
    "\n",
    "        # Parse the XML file\n",
    "        with open(xml_file, 'rb') as xml_file:\n",
    "            xml_doc = etree.parse(xml_file)\n",
    "\n",
    "        # Validate the XML file against the XSD schema\n",
    "        schema.assertValid(xml_doc)\n",
    "        return \"XML is valid.\"\n",
    "\n",
    "    except etree.XMLSchemaError as e:\n",
    "        return \"XML is invalid: \" + str(e)\n",
    "    except Exception as e:\n",
    "        return \"An error occurred: \" + str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages.append(gpt_response)\n",
    "# Example usage\n",
    "xsd_file = 'app/resources/context/wheeled_bots/schema.xsd'\n",
    "xml_file = 'app/gpt_outputs/gpt_example.xml'\n",
    "ret = validate_xml(xsd_file, xml_file)\n",
    "print(ret)\n",
    "# messages.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(xml_file):\n",
    "    with open(xml_file, \"rb\") as fp:\n",
    "        xml_doc: etree._ElementTree = etree.parse(fp)\n",
    "\n",
    "    root: etree._Element = xml_doc.getroot()\n",
    "    xsi = root.nsmap['xsi']\n",
    "    location = root.attrib['{' + xsi + \"}schemaLocation\"]\n",
    "    return location.split(root.nsmap[None] + \" \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "xml_file = 'app/gpt_outputs/gpt_example.xml'\n",
    "ret = location(xml_file)\n",
    "print(ret)\n",
    "# messages.append(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = (\n",
    "    \"\"\"\n",
    "{ \n",
    "\"type\": \"FeatureCollection\",\n",
    "\"features\": [\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "gps: str = (\n",
    "    \"\"\"\n",
    "    {{\n",
    "      \"type\": \"Feature\",\n",
    "      \"geometry\": {{\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [{}, {}]\n",
    "      }},\n",
    "      \"properties\": {{\n",
    "        \"marker-symbol\": \"{}-tree\"\n",
    "      }}\n",
    "    }},\"\"\"\n",
    ")\n",
    "\n",
    "tree_type: str = \"pistachio\"\n",
    "i = 0\n",
    "dir = True\n",
    "tree_num = 0\n",
    "\n",
    "for gps_coord in coors:\n",
    "    out = gps.format(gps_coord[0], gps_coord[1], tree_type)\n",
    "    text += out\n",
    "    i += 1\n",
    "\n",
    "# with open(\"resources/reza_waypoints.txt\", \"r\") as fp:\n",
    "#     for line in fp.readlines():\n",
    "#         gps_coord = line.split(\" \")\n",
    "#         # only want trees\n",
    "#         if gps_coord[2] == 0:\n",
    "#             continue\n",
    "#         if i % 18 == 0:\n",
    "#             dir = ~dir\n",
    "#             tree_num -= 18\n",
    "#         out = gps.format(gps_coord[0], gps_coord[1], tree_type)\n",
    "#         text += out\n",
    "#         i += 1\n",
    "\n",
    "# remove last comma\n",
    "text = text[:-1]\n",
    "text += \"\"\"  \n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"app/resources/context/wheeled_bots/ucm20_2m.geojson\", \"w\") as fp:\n",
    "    fp.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm\n",
    "import json\n",
    "import geopy.distance\n",
    "import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_data = {}\n",
    "with open(\"app/resources/context/wheeled_bots/ucm_graph20.geojsonl\", \"r\") as fp:\n",
    "    for line in fp:\n",
    "        data = json.loads(line.strip())\n",
    "        geojson_data[data['properties']['id']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = [0, 2, 7, 18, 19]\n",
    "# sol = [0, 2, 15, 18, 29]\n",
    "# sol = [0, 7, 25, 36, 39]\n",
    "cost = 0\n",
    "for s in range(len(sol)-1):\n",
    "    lon1, lat1 = geojson_data[sol[s]]['geometry']['coordinates']\n",
    "    lon2, lat2 = geojson_data[sol[s+1]]['geometry']['coordinates']\n",
    "    # cost += geopy.distance.distance((lat1, lon1), (lat2, lon2)).meters\n",
    "    cost += haversine.haversine((lat1, lon1), (lat2, lon2), unit=haversine.Unit.METERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "budget: 19.9773073572487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon1, lat1 = geojson_data[19]['geometry']['coordinates']\n",
    "lon2, lat2 = geojson_data[18]['geometry']['coordinates']\n",
    "geopy.distance.distance((lat1, lon1), (lat2, lon2)).meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13.686394049112627 * (2/1.3694051976193413)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app/resources/context/wheeled_bots/kml/graph20.kml\", \"rb\") as fp:\n",
    "    root = etree.parse(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_e: etree._Element = root.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = \"{\" + root_e.nsmap[None] + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pms = root_e.find(ns + \"Document\").findall(ns + \"Placemark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coors = []\n",
    "for pm in pms:\n",
    "    coor = pm.find(ns + \"Point\").find(ns + \"coordinates\").text.split(',')\n",
    "    coor = [float(c) for c in coor]\n",
    "    # print(coor[1])\n",
    "    # e, n, _, _ = utm.from_latlon(coor[1], coor[0])\n",
    "    e = coor[0]\n",
    "    n = coor[1]\n",
    "\n",
    "    coors.append((e, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "with open('path.txt', 'r') as fp:\n",
    "    for f in fp:\n",
    "        coor = f.split(',')\n",
    "        coor = [float(c) for c in coor]\n",
    "        e, n, _, _ = utm.from_latlon(coor[1], coor[0])\n",
    "\n",
    "        path.append((e, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arrow(line, position=None, direction='right', size=15, color=None):\n",
    "    \"\"\"\n",
    "    add an arrow to a line.\n",
    "\n",
    "    line:       Line2D object\n",
    "    position:   x-position of the arrow. If None, mean of xdata is taken\n",
    "    direction:  'left' or 'right'\n",
    "    size:       size of the arrow in fontsize points\n",
    "    color:      if None, line color is taken.\n",
    "    \"\"\"\n",
    "    if color is None:\n",
    "        color = line.get_color()\n",
    "\n",
    "    xdata = line.get_xdata()\n",
    "    ydata = line.get_ydata()\n",
    "\n",
    "    if position is None:\n",
    "        position = xdata.mean()\n",
    "    # find closest index\n",
    "    # start_ind = np.argmin(np.absolute(xdata - position))\n",
    "    start_ind = 0\n",
    "    if direction == 'right':\n",
    "        end_ind = start_ind + 1\n",
    "    else:\n",
    "        end_ind = start_ind - 1\n",
    "\n",
    "    line.axes.annotate('',\n",
    "        xytext=(xdata[start_ind], ydata[start_ind]),\n",
    "        xy=(xdata[end_ind], ydata[end_ind]),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=color),\n",
    "        size=size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coors = np.array(coors)\n",
    "path = np.array(path)\n",
    "\n",
    "img = plt.imread(\"app/resources/context/wheeled_bots/images/img.png\")\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# ax.imshow(img, extent=[-0.1, 1, -0.3, 1.25])\n",
    "ax.imshow(img, extent=[np.min(coors[:,0])-0.75, np.max(coors[:,0])+1, np.min(coors[:,1])-0.5, np.max(coors[:,1])+0.5])\n",
    "# ax.imshow(img, extent=[np.min(coors[:,0]), np.max(coors[:,0]), np.min(coors[:,1]), np.max(coors[:,1])])\n",
    "# weights = np.arange(0, len(path[20:-29,0]))\n",
    "for i in range(26, len(path)-11, 1):\n",
    "    line = plt.plot(path[i:i+2,0], path[i:i+2,1], 'black')[0]\n",
    "    if i % 4 == 0:\n",
    "        add_arrow(line, direction='left', color='black', size=20, position=0)\n",
    "plt.scatter(x = coors[0,0], y = coors[0,1], color='green')\n",
    "plt.scatter(x = coors[1:-1,0], y = coors[1:-1,1], color='blue')\n",
    "plt.scatter(x = coors[-1,0], y = coors[-1,1], color='red')\n",
    "plt.axis('off')\n",
    "# plt.show()\n",
    "plt.savefig(\"test.png\",bbox_inches='tight', pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import webcolors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        distance = ((r_c - requested_color[0]) ** 2 +\n",
    "                    (g_c - requested_color[1]) ** 2 +\n",
    "                    (b_c - requested_color[2]) ** 2)\n",
    "        min_colors[distance] = name\n",
    "    return min_colors[min(min_colors.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_name(rgb):\n",
    "    try:\n",
    "        return webcolors.rgb_to_name(rgb)\n",
    "    except ValueError:\n",
    "        return closest_color(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoCap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = videoCap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    results = yolo.track(frame, stream=True)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        # get the classes names\n",
    "        classes_names = result.names\n",
    "    \n",
    "    # iterate over each box\n",
    "        for box in result.boxes:\n",
    "            # check if confidence is greater than 40 percent\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # get the class\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # get the class name\n",
    "                class_name = classes_names[cls]\n",
    "\n",
    "                # get the respective colour\n",
    "                colour = getColours(cls)\n",
    "\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
    "\n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "                average_color = np.mean(roi, axis=(0, 1))  # [R, G, B]\n",
    "                color_name = rgb_to_name(tuple(map(int, average_color)))\n",
    "\n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(frame, f'{color_name + \" \" + classes_names[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                \n",
    "    # show the image\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture and destroy all windows\n",
    "videoCap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_FN: str = \"\"\"\n",
    "proctype select_{}() {{\n",
    "    int i;\n",
    "    select (i : {}..{});\n",
    "    {} = i;\n",
    "    printf(\"{}: %d\\n\", {});\n",
    "}}\n",
    "\"\"\"\n",
    "SENSOR_FN.format(\"temp\", 29, 31, \"temp\", \"temp\", \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ltl = \"\"\" \n",
    "<>( init && X (moveMiddle && X (picMiddle && X ((temp_low && X (co2Middle && X moveDown5)) || \n",
    "(!temp_low && X moveDown5))) && X (picDown5 && X ((temp_low2 && X co2Down5) || !temp_low2))) \n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ltl = \"\"\" <>(\n",
    "init && X (moveMiddle && X (picMiddle && X ((temp_low && \n",
    "X (co2Middle && X (moveDown5 && X (picDown5 && X ((temp_low2 && X co2Down5) || !temp_low2))))) || \n",
    "(!temp_low && X (moveDown5 && X (picDown5 && X ((temp_low2 && X co2Down5) || !temp_low2)))))))\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltl = \"\"\" <>(moveToNorthwestCorner && X (orientEastForFirstRow && X (swapToChineseBittermelon && X (activateSeederFirstRow && X (plantFirstChineseRow && X (deactivateSeederEndFirstRow && X (turnSouthAfterFirstRow && X (moveToSecondRowPosition && X (orientWestForSecondRow && X (activateSeederSecondRow && X (plantSecondChineseRow && X (deactivateSeederEndSecondRow && X (turnSouthAfterSecondRow && X (moveToThirdRowPosition && X (orientEastForThirdRow && X (swapToIndianBittermelon && X (activateSeederThirdRow && X (plantIndianRow && X deactivateSeederFinal))))))))))))))))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spot.translate(ltl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in spot.automata('5_nest.aut'):\n",
    "    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 for s in range(a.num_states()) for t in a.out(s) if t.dst != s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(a.accepting_run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.spot_utils import generate_accepting_run_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs: list[str] = [\n",
    "    generate_accepting_run_string(a) for _ in range(5)\n",
    "]\n",
    "runs_str: str = \"\\n\".join(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in a.out(a.get_init_state_number()):\n",
    "    print(e.dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltl = \"\"\"\n",
    "    (MoveToFirstPistachioTree.action.actionType == 0 &&\n",
    "    X(MoveToFirstPistachioTree.action.actionType == moveToGPSLocation &&\n",
    "    X(TakePictureAtFirstTree.action.actionType == takeThermalPicture &&\n",
    "    X(MoveToSecondPistachioTree.action.actionType == moveToGPSLocation &&\n",
    "    X(MoveToThirdPistachioTree.action.actionType == moveToGPSLocation &&\n",
    "    X(TakePictureAtThirdTree.action.actionType == takeThermalPicture &&\n",
    "    X(MoveToFourthPistachioTree.action.actionType == moveToGPSLocation &&\n",
    "    X(MoveToFifthPistachioTree.action.actionType == moveToGPSLocation &&\n",
    "    X(TakePictureAtFifthTree.action.actionType == takeThermalPicture)\n",
    "    ))))))))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.os_utils import execute_shell_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, e = execute_shell_cmd(\n",
    "            [\"spin\", \"-f\", ltl]\n",
    "        )\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generalize_ltl_fully(expression: str) -> str:\n",
    "    # --- Step 1: Strip 'ltl <label> {' and trailing '}' ---\n",
    "    expression = expression.strip()\n",
    "    expression = re.sub(r'^ltl\\s+\\w+\\s*{', '', expression).strip()\n",
    "    expression = re.sub(r'}\\s*$', '', expression).strip()\n",
    "\n",
    "    # --- Step 2: Deduplicate (A == 0 && X(A == ...) ---\n",
    "    def dedup_initial_action_zero(match):\n",
    "        name1, name2, inner = match.group(1), match.group(2), match.group(3)\n",
    "        if name1 == name2:\n",
    "            # Return just name1 lowercase plus the rest inside inner (which is the rest of the expression inside the parentheses)\n",
    "            return f\"{name1.lower()} && {inner}\"\n",
    "        return match.group(0)\n",
    "\n",
    "    expression = re.sub(\n",
    "        r'\\(\\s*([A-Za-z0-9_]+)\\.action\\.actionType\\s*==\\s*0\\s*&&\\s*X\\s*\\(\\s*([A-Za-z0-9_]+)\\.action\\.actionType\\s*==\\s*[A-Za-z0-9_]+\\s*&&\\s*(.+)\\)\\s*\\)',  # notice the outer closing parens at end\n",
    "        dedup_initial_action_zero,\n",
    "        expression,\n",
    "        flags=re.DOTALL\n",
    "    )\n",
    "\n",
    "\n",
    "    expression = re.sub(\n",
    "        r'\\(\\s*([A-Za-z0-9_]+)\\.action\\.actionType\\s*==\\s*0\\s*&&\\s*X\\s*\\(\\s*([A-Za-z0-9_]+)\\.action\\.actionType\\s*==\\s*[A-Za-z0-9_]+\\s*&&',\n",
    "        dedup_initial_action_zero,\n",
    "        expression\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Remove outer parentheses if any ---\n",
    "    expression = expression.strip()\n",
    "    if expression.startswith('(') and expression.endswith(')'):\n",
    "        expression = expression[1:-1].strip()\n",
    "\n",
    "    # --- Step 4: Replace .action.actionType == something ---\n",
    "    expression = re.sub(\n",
    "        r'\\b([A-Za-z0-9_]+)\\.action\\.actionType\\s*==\\s*[A-Za-z0-9_]+',\n",
    "        lambda m: m.group(1).lower(),\n",
    "        expression\n",
    "    )\n",
    "\n",
    "    # --- Step 5: Replace comparisons with labels and negations ---\n",
    "    def replace_comparator(match):\n",
    "        var = match.group(1).lower()\n",
    "        op = match.group(2)\n",
    "        val = match.group(3)\n",
    "\n",
    "        mapping = {\n",
    "            '<': ('low', False),\n",
    "            '>=': ('low', True),\n",
    "            '<=': ('high', False),\n",
    "            '>': ('high', True),\n",
    "            '==': ('equal', False),\n",
    "            '!=': ('equal', True),\n",
    "        }\n",
    "\n",
    "        if op not in mapping:\n",
    "            return match.group(0)\n",
    "\n",
    "        prefix, neg = mapping[op]\n",
    "        token = f\"{prefix}{var}_{val}\"\n",
    "\n",
    "        if neg:\n",
    "            return f\"!{token}\"\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "    expression = re.sub(\n",
    "        r'\\b([A-Za-z0-9_]+)\\s*(<=|>=|<|>|==|!=)\\s*(-?\\d+(?:\\.\\d+)?)',\n",
    "        replace_comparator,\n",
    "        expression\n",
    "    )\n",
    "\n",
    "    # --- Step 6: Clean logical operators spacing ---\n",
    "    expression = re.sub(r'\\s*(&&|\\|\\|)\\s*', r' \\1 ', expression)\n",
    "\n",
    "    # --- Step 7: Ensure space before temporal operator X( ---\n",
    "    expression = re.sub(r'\\s*X\\s*\\(', r' X(', expression)\n",
    "\n",
    "    # --- Step 8: Remove line breaks and collapse whitespace ---\n",
    "    expression = re.sub(r'\\s+', ' ', expression).strip()\n",
    "\n",
    "    # --- Step 10: Wrap in <> if not already ---\n",
    "    if not expression.startswith('<>'):\n",
    "        expression = f\"<>({expression})\"\n",
    "\n",
    "    return expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generalize_ltl_fully(ltl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spot\n",
    "spot.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spot.translate(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "def convert_geojson_file_to_kml(input_path: str, output_path: str):\n",
    "    # Read the GeoJSON file\n",
    "    with open(input_path, 'r') as f:\n",
    "        geojson = json.load(f)\n",
    "\n",
    "    # Create root KML element\n",
    "    kml = Element(\"kml\", xmlns=\"http://www.opengis.net/kml/2.2\")\n",
    "    document = SubElement(kml, \"Document\")\n",
    "\n",
    "    # Convert each feature\n",
    "    for i, feature in enumerate(geojson.get(\"features\", [])):\n",
    "        coords = feature[\"geometry\"][\"coordinates\"]\n",
    "        symbol = feature[\"properties\"].get(\"marker-symbol\", \"unknown\")\n",
    "\n",
    "        placemark = SubElement(document, \"Placemark\")\n",
    "        name = SubElement(placemark, \"name\")\n",
    "        name.text = f\"{symbol} {i+1}\"\n",
    "\n",
    "        point = SubElement(placemark, \"Point\")\n",
    "        SubElement(point, \"coordinates\").text = f\"{coords[1]},{coords[0]},0\"\n",
    "\n",
    "    # Beautify and write KML output\n",
    "    rough_string = tostring(kml, 'utf-8')\n",
    "    pretty_kml = parseString(rough_string).toprettyxml(indent=\"  \")\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(pretty_kml)\n",
    "\n",
    "    print(f\"KML file written to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_geojson_file_to_kml('/gpt-mission-planner/app/resources/context/wheeled_bots/reza_medium.geojson', '/gpt-mission-planner/app/resources/context/wheeled_bots/kml/reza_medium.kml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.gps_utils import TreePlacementGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof. ehsani plot (small/right)\n",
    "polygon_coords = [\n",
    "(-120.42079453, 37.26643908),\n",
    "(-120.42012318, 37.26644777),\n",
    "(-120.42011635, 37.26578860),\n",
    "(-120.42079999, 37.26578751)\n",
    "]\n",
    "\n",
    "tree_counts = [(8, 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nextdoor neighbor plot (partial)\n",
    "polygon_coords = [\n",
    "(-120.41798082249016, 37.26625689930845),\n",
    "(-120.4156878224599, 37.266997779448516),\n",
    "(-120.41553074370994, 37.26699591367558),\n",
    "(-120.41544804624566, 37.26694945401283),\n",
    "(-120.4182510184941, 37.26604473557503),\n",
    "(-120.41806543593748, 37.266176769362865)\n",
    "]\n",
    "\n",
    "tree_counts = [(61, 1), (67, 1), (73, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof. ehsani plot\n",
    "polygon_coords = [\n",
    "(-120.42204215514842, 37.26708461749112),\n",
    "(-120.42088955723558, 37.26709159286849),\n",
    "(-120.42088955723558, 37.266441136149666),\n",
    "(-120.42012318, 37.26644777),\n",
    "(-120.42011635, 37.26578860),\n",
    "(-120.42203840154214, 37.26577378482724)\n",
    "]\n",
    "top_edge_start = (-120.42204215514842, 37.26708461749112)\n",
    "top_edge_end   = (-120.42088955723558, 37.26709159286849)\n",
    "\n",
    "tree_counts = [13] * 17 + [21] * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"app/config/localhost.yaml\", \"r\") as file:\n",
    "    config_yaml: dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.gps_utils import TreePlacementGenerator\n",
    "tpg = TreePlacementGenerator(config_yaml[\"farm_polygon\"][\"points\"], config_yaml[\"farm_polygon\"][\"dimensions\"])\n",
    "_ = tpg.generate_tree_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpg.tree_points[136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tpg.replace_tree_ids_with_gps(\"/gpt-mission-planner/app/gpt_outputs/rap/original.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "    model=\"ollama/gpt-oss:20b\",  # Specify the model, including the provider prefix\n",
    "    messages=[{\"content\": \"hello\", \"role\": \"user\"}],\n",
    "    api_base=\"http://localhost:11434\"  # The API base URL of your local Ollama instance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original grid:\n",
      " [[[  37.26578751 -120.42079999]\n",
      "  [  37.26578751 -120.42011635]]\n",
      "\n",
      " [[  37.26644777 -120.42079999]\n",
      "  [  37.26644777 -120.42011635]]]\n",
      "Shifted grid:\n",
      " [[[  37.26578751 -120.42082263]\n",
      "  [  37.26578751 -120.42013899]]\n",
      "\n",
      " [[  37.26644777 -120.42082263]\n",
      "  [  37.26644777 -120.42013899]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "\n",
    "# Polygon coordinates (lon, lat)\n",
    "polygon_coords = [\n",
    "    (-120.42079453, 37.26643908),\n",
    "    (-120.42012318, 37.26644777),\n",
    "    (-120.42011635, 37.26578860),\n",
    "    (-120.42079999, 37.26578751)\n",
    "]\n",
    "\n",
    "polygon = Polygon(polygon_coords)\n",
    "\n",
    "# Example: generate a simple grid inside polygon\n",
    "# For demonstration, we just make 2x2 points along rows and columns\n",
    "grid_rows = 2\n",
    "grid_cols = 2\n",
    "\n",
    "minx, miny, maxx, maxy = polygon.bounds\n",
    "\n",
    "lons = np.linspace(minx, maxx, grid_cols)\n",
    "lats = np.linspace(miny, maxy, grid_rows)\n",
    "\n",
    "# Create 2D grid of points (rows x cols)\n",
    "gps_grid = np.array([\n",
    "    [[lat, lon] for lon in lons]  # lat = y, lon = x\n",
    "    for lat in lats\n",
    "])\n",
    "\n",
    "# Function to shift a column to the left (perpendicular)\n",
    "def shift_points_left(column_points, meters_left):\n",
    "    # column_points: Nx2 array [lat, lon]\n",
    "    start = column_points[0]\n",
    "    end = column_points[-1]\n",
    "\n",
    "    # Convert lat/lon to meters (approx)\n",
    "    lat_mean = np.mean(column_points[:,0])\n",
    "    lat_scale = 111000.0\n",
    "    lon_scale = 111000.0 * np.cos(np.radians(lat_mean))\n",
    "\n",
    "    start_m = np.array([start[1]*lon_scale, start[0]*lat_scale])\n",
    "    end_m   = np.array([end[1]*lon_scale, end[0]*lat_scale])\n",
    "\n",
    "    column_vector = end_m - start_m\n",
    "\n",
    "    # Perpendicular vector to the left\n",
    "    perp_vector = np.array([-column_vector[1], column_vector[0]])\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector) * meters_left\n",
    "\n",
    "    # Shift all points\n",
    "    shifted_points_m = np.array([\n",
    "        [pt[1]*lon_scale, pt[0]*lat_scale] + perp_vector\n",
    "        for pt in column_points\n",
    "    ])\n",
    "\n",
    "    # Convert back to lat/lon\n",
    "    shifted_points = np.array([\n",
    "        [y/lat_scale, x/lon_scale] for x, y in shifted_points_m\n",
    "    ])\n",
    "\n",
    "    return shifted_points\n",
    "\n",
    "# Apply shift to all columns\n",
    "rows, cols, _ = gps_grid.shape\n",
    "shifted_grid = np.empty_like(gps_grid)\n",
    "\n",
    "for j in range(cols):\n",
    "    column = gps_grid[:, j, :]\n",
    "    shifted_column = shift_points_left(column, meters_left=2.0)  # shift 2m left\n",
    "    shifted_grid[:, j, :] = shifted_column\n",
    "\n",
    "print(\"Original grid:\\n\", gps_grid)\n",
    "print(\"Shifted grid:\\n\", shifted_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
